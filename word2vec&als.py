# -*- coding: utf-8 -*-
"""Word2vec&ALS.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NSxqB5L9jfhpD_Li3IvhwAuaj_0gEHPA
"""

!pip install --upgrade --force-reinstall numpy==1.26.4 pandas==2.2.2 gensim implicit

import sys
try:
    import gensim
    import implicit
except Exception:
    # Install only missing heavy libs (will restart runtime only if necessary in some envs,
    # but this is minimal and typical for Colab it's fine)
    !pip install --quiet gensim implicit
    import importlib
    importlib.invalidate_caches()

# Optional: seaborn for nicer plots
try:
    import seaborn as sns
    sns_available = True
except Exception:
    sns_available = False

import os
import re
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from gensim.models import Word2Vec
from sklearn.metrics.pairwise import cosine_similarity
from scipy.sparse import coo_matrix
from implicit.als import AlternatingLeastSquares

# -----------------------------------------------------------
# Config (ubah path jika perlu)
# -----------------------------------------------------------
DRIVE_PATHS_TO_TRY = [
    "/content/drive/My Drive/amazon.csv"
]

# -----------------------------------------------------------
# Mount Drive (Colab). Jika tidak pakai Colab, skip ini.
# -----------------------------------------------------------
try:
    from google.colab import drive
    drive.mount('/content/drive', force_remount=False)
except Exception:
    # not running in Colab or mount failed; proceed (user may run locally)
    pass

# -----------------------------------------------------------
# Load dataset (cari path yang tersedia)
# -----------------------------------------------------------
df = None
for p in DRIVE_PATHS_TO_TRY:
    if os.path.exists(p):
        df = pd.read_csv(p)
        print(f"Loaded dataset from: {p}")
        break

if df is None:
    raise FileNotFoundError(
        "File not found. Please upload 'amazon.csv' to Colab Drive or set the correct path in DRIVE_PATHS_TO_TRY."
    )

print("Initial dataframe shape:", df.shape)
print(df.columns.tolist())
print(df.head(3))

# -----------------------------------------------------------
# Quick checks & missing values
# -----------------------------------------------------------
print("\nMissing counts:")
print(df.isnull().sum())

# -----------------------------------------------------------
# Data cleaning: ensure about_product and rating exist
# -----------------------------------------------------------
if 'about_product' not in df.columns:
    # Fallback: if there's no 'about_product', try 'product_description' or use product_name as text
    fallback_cols = [c for c in ['product_description', 'description', 'product_info', 'product_details'] if c in df.columns]
    if fallback_cols:
        df['about_product'] = df[fallback_cols[0]].astype(str)
    else:
        # fallback to product_name
        df['about_product'] = df['product_name'].astype(str)

# Drop rows missing essential columns
df = df.dropna(subset=['about_product', 'rating']).copy()
print("After dropping rows with missing about_product/rating:", df.shape)

# -----------------------------------------------------------
# Clean rating column: extract numeric part (e.g., "4.0 out of 5" => 4.0)
# -----------------------------------------------------------
df['rating'] = df['rating'].astype(str).str.extract(r'(\d+(\.\d+)?)')[0]
df['rating'] = pd.to_numeric(df['rating'], errors='coerce')
df = df.dropna(subset=['rating']).copy()
df['rating'] = df['rating'].astype(float)
print("After cleaning rating:", df.shape)
print("Rating dtype:", df['rating'].dtype)

# Optional: visualize distribution
if sns_available:
    plt.figure(figsize=(8,4))
    sns.histplot(df['rating'], bins=20)
    plt.title("Distribusi Rating")
    plt.show()
else:
    plt.figure(figsize=(8,4))
    plt.hist(df['rating'].dropna(), bins=20)
    plt.title("Distribusi Rating")
    plt.show()

# -----------------------------------------------------------
# CONTENT-BASED (Word2Vec)
# -----------------------------------------------------------
print("\n=== Content-Based: Word2Vec ===")

# Tokenize descriptions (simple). You may replace with better tokenizer (spacy, nltk).
def tokenize_text(text):
    # keep words only, lowercased
    return re.findall(r'\w+', str(text).lower())

df['tokens'] = df['about_product'].apply(tokenize_text)

# Train Word2Vec on tokens (if dataset small, set min_count=1)
w2v_model = Word2Vec(
    sentences=df['tokens'].tolist(),
    vector_size=100,
    window=5,
    min_count=1,
    workers=4,
    seed=42
)

# compute product vector = mean(word vectors)
def product_vector(tokens):
    vecs = [w2v_model.wv[w] for w in tokens if w in w2v_model.wv]
    if not vecs:
        return np.zeros(w2v_model.vector_size, dtype=float)
    return np.mean(vecs, axis=0)

df['vector'] = df['tokens'].apply(product_vector)
product_embeddings = np.vstack(df['vector'].values)  # shape: (n_products, dim)
print("Product embeddings shape:", product_embeddings.shape)

# cosine similarity (careful: large N => heavy)
# We compute similarity on demand inside function to avoid huge memory if dataset big.
def content_based_recommendations(product_title, top_k=5):
    if product_title not in df['product_name'].values:
        return []
    idx = df.index[df['product_name'] == product_title][0]
    v = product_embeddings[idx].reshape(1, -1)
    sims = cosine_similarity(v, product_embeddings)[0]
    order = sims.argsort()[::-1]
    # skip itself
    order = [i for i in order if i != idx]
    top_idx = order[:top_k]
    return df.iloc[top_idx][['product_name', 'rating']]

# Quick example (guard for empty product_name)
if 'product_name' in df.columns and not df['product_name'].isnull().all():
    example_prod = df['product_name'].iloc[0]
    print("Example content-based recommendations for:", example_prod)
    print(content_based_recommendations(example_prod, top_k=5))
else:
    print("No 'product_name' column present -- skip CB example")

import os
os.environ["OPENBLAS_NUM_THREADS"] = "1"

# -----------------------------------------------------------
# COLLABORATIVE FILTERING: ALS (implicit)
# -----------------------------------------------------------
print("\n=== Collaborative Filtering: ALS (implicit) ===")

# Ensure user_id and product_name exist
if 'user_id' not in df.columns or 'product_name' not in df.columns:
    raise KeyError("Dataset must contain 'user_id' and 'product_name' columns for collaborative filtering.")

# encode user and item to integer codes
df['user_code'] = df['user_id'].astype('category').cat.codes.astype(int)
df['item_code'] = df['product_name'].astype('category').cat.codes.astype(int)

# ensure numeric
df['user_code'] = df['user_code'].astype(int)
df['item_code'] = df['item_code'].astype(int)
df['rating'] = df['rating'].astype(float)

# build sparse matrix (users x items)
ratings_matrix = coo_matrix(
    (df['rating'].values, (df['user_code'].values, df['item_code'].values))
)
print("Ratings matrix shape (users x items):", ratings_matrix.shape)

# Train ALS model (implicit expects item-user matrix for fit)
als_model = AlternatingLeastSquares(factors=50, regularization=0.1, iterations=20, use_gpu=False)
# fit takes item_users matrix
als_model.fit(ratings_matrix.T)

# mapping helpers
user_code_to_id = dict(enumerate(df['user_id'].astype('category').cat.categories))
item_code_to_name = dict(enumerate(df['product_name'].astype('category').cat.categories))
# reverse maps (if needed)
user_id_to_code = {v: k for k, v in user_code_to_id.items()}

def als_recommend(user_id, top_k=5):
    """
    Robust ALS recommend wrapper:
    - menangani keluaran recommend() yang bisa berupa list of tuples
      atau tuple of arrays.
    - mengembalikan list nama produk.
    """
    if user_id not in user_id_to_code:
        return []

    ucode = user_id_to_code[user_id]
    user_items = ratings_matrix.tocsr()[ucode]

    # panggil recommend
    recs = als_model.recommend(ucode, user_items, N=top_k)

    # normalisasi ke list of (item_code, score)
    rec_list = []

    # Kasus 1: recommend mengembalikan tuple (ids_array, scores_array)
    if isinstance(recs, tuple) and len(recs) == 2:
        ids, scores = recs
        rec_list = [(int(i), float(s)) for i, s in zip(ids, scores)]

    else:
        # Kasus 2: recommend mengembalikan iterable (mis. list of (id, score))
        try:
            for entry in recs:
                # entry bisa berupa array/tuple seperti [id, score]
                if hasattr(entry, '__len__') and len(entry) >= 2:
                    rec_list.append((int(entry[0]), float(entry[1])))
                else:
                    # entry hanya id saja
                    rec_list.append((int(entry), None))
        except Exception:
            # fallback: konversi numpy array dua dimensi
            import numpy as _np
            arr = _np.asarray(recs)
            if arr.ndim == 2 and arr.shape[1] >= 2:
                rec_list = [(int(x[0]), float(x[1])) for x in arr]
            else:
                rec_list = [(int(x), None) for x in arr.ravel()]

    # ambil nama produk dari kode item
    rec_names = []
    for item_code, score in rec_list:
        name = item_code_to_name.get(item_code, None)
        if name is not None:
            rec_names.append((name, score))
        else:
            # jika mapping tidak ada, masukkan kode saja
            rec_names.append((f"<item_code:{item_code}>", score))

    return rec_names

# Example ALS recommendation
example_user = df['user_id'].iloc[0]
print("ALS recommendations (name, score):", als_recommend(example_user, top_k=5))
print(als_recommend(example_user, top_k=5))

# -----------------------------------------------------------
# Simple evaluation & top/bottom products
# -----------------------------------------------------------
print("\n=== Evaluation & Summary ===")
top_products = df.groupby('product_name')['rating'].mean().sort_values(ascending=False).head(5)
bottom_products = df.groupby('product_name')['rating'].mean().sort_values(ascending=True).head(5)
print("Top 5 products by mean rating:\n", top_products)
print("Bottom 5 products by mean rating:\n", bottom_products)

# Plot top/bottom (optional)
plt.figure(figsize=(10,5))
plt.bar(top_products.index, top_products.values, label='Top', alpha=0.8)
plt.bar(bottom_products.index, bottom_products.values, label='Bottom', alpha=0.8)
plt.xticks(rotation=45, ha='right')
plt.ylabel('Mean Rating')
plt.title('Top & Bottom Products by Mean Rating')
plt.legend()
plt.tight_layout()
plt.show()